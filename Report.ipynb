{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Aman Chopra  \n",
    "**Purdue Email:** chopra21@purdue.edu  \n",
    "**[Github Repo](https://github.com/amanichopra/CNN-Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources Used\n",
    "- https://zhenye-na.github.io/2018/09/28/pytorch-cnn-cifar10.html\n",
    "- https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "- Constructed CNN with Keras for MNIST digits (99% accuracy), MNIST fashion (92% accuracy), CIFAR-10 (73% accuracy), CIFAR-100 fine (43% accuracy), and CIFAR-100 coarse (56% accuracy) datasets.\n",
    "- Implemented support for saving and loading models to avoid retraining.\n",
    "- Incorporated functionality for augmentation and random cropping of input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) How is a CNN superior to standard ANNs for image processing?**\n",
    "\n",
    "The main advantage of CNNs over standard ANNs for image processing is that they preserve the spatial interactions in images. They are also effective in capturing the relevant features of images, similar to process of human vision processing. Just like humans, CNNs begin with simple cells capturing high-level attributes and end with more complex cells capturing low-level attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Why do we sometimes use pooling in CNNs?**\n",
    "\n",
    "Pooling is useful to help reduce the space complexity of the network and compute fewer parameters. It significantly reduces overhead during training, while still retaining the important features of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Why do you think the cifar datasets are harder than mnist?**\n",
    "\n",
    "The CIFAR datasets are harder to classify that MNIST probably due to the following reasons:\n",
    "- CIFAR images are RGB unlike the black & white MNIST images, which adds more complexity.\n",
    "- CIFAR images have varied backgrounds and orientations for the same objects. For example, airplanes in the dataset are in different settings and are pictured in different angles. \n",
    "- MNIST has much fewer class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the results on each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_tuning import getRawData, preprocessData, trainModel, runModel, evalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mnist_d\n",
      "Shape of xTrain dataset: (60000, 28, 28).\n",
      "Shape of yTrain dataset: (60000,).\n",
      "Shape of xTest dataset: (10000, 28, 28).\n",
      "Shape of yTest dataset: (10000,).\n",
      "New shape of xTrain dataset: (60000, 28, 28, 1).\n",
      "New shape of xTest dataset: (10000, 28, 28, 1).\n",
      "New shape of yTrain dataset: (60000, 10).\n",
      "New shape of yTest dataset: (10000, 10).\n",
      "Building and training TF_CNN.\n",
      "Testing TF_CNN.\n",
      "Classifier algorithm: tf_conv\n",
      "Classifier accuracy: 99.080000%\n",
      "\n",
      "Dataset: mnist_f\n",
      "Shape of xTrain dataset: (60000, 28, 28).\n",
      "Shape of yTrain dataset: (60000,).\n",
      "Shape of xTest dataset: (10000, 28, 28).\n",
      "Shape of yTest dataset: (10000,).\n",
      "New shape of xTrain dataset: (60000, 28, 28, 1).\n",
      "New shape of xTest dataset: (10000, 28, 28, 1).\n",
      "New shape of yTrain dataset: (60000, 10).\n",
      "New shape of yTest dataset: (10000, 10).\n",
      "Building and training TF_CNN.\n",
      "Testing TF_CNN.\n",
      "Classifier algorithm: tf_conv\n",
      "Classifier accuracy: 92.920000%\n",
      "\n",
      "Dataset: cifar_10\n",
      "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "Shape of yTrain dataset: (50000, 1).\n",
      "Shape of xTest dataset: (10000, 32, 32, 3).\n",
      "Shape of yTest dataset: (10000, 1).\n",
      "New shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "New shape of xTest dataset: (10000, 32, 32, 3).\n",
      "New shape of yTrain dataset: (50000, 10).\n",
      "New shape of yTest dataset: (10000, 10).\n",
      "Building and training TF_CNN.\n",
      "Testing TF_CNN.\n",
      "Classifier algorithm: tf_conv\n",
      "Classifier accuracy: 73.880000%\n",
      "\n",
      "Dataset: cifar_100_c\n",
      "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "Shape of yTrain dataset: (50000, 1).\n",
      "Shape of xTest dataset: (10000, 32, 32, 3).\n",
      "Shape of yTest dataset: (10000, 1).\n",
      "New shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "New shape of xTest dataset: (10000, 32, 32, 3).\n",
      "New shape of yTrain dataset: (50000, 20).\n",
      "New shape of yTest dataset: (10000, 20).\n",
      "Building and training TF_CNN.\n",
      "Testing TF_CNN.\n",
      "Classifier algorithm: tf_conv\n",
      "Classifier accuracy: 56.560000%\n",
      "\n",
      "Dataset: cifar_100_f\n",
      "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "Shape of yTrain dataset: (50000, 1).\n",
      "Shape of xTest dataset: (10000, 32, 32, 3).\n",
      "Shape of yTest dataset: (10000, 1).\n",
      "New shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "New shape of xTest dataset: (10000, 32, 32, 3).\n",
      "New shape of yTrain dataset: (50000, 100).\n",
      "New shape of yTest dataset: (10000, 100).\n",
      "Building and training TF_CNN.\n",
      "Testing TF_CNN.\n",
      "Classifier algorithm: tf_conv\n",
      "Classifier accuracy: 43.940000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mods = {'mnist_d':None, 'mnist_f':None, 'cifar_10':None, 'cifar_100_c':None, 'cifar_100_f':None}\n",
    "acc = {dataset: None for dataset in mods}\n",
    "for dataset in mods:\n",
    "    raw = getRawData(dataset)\n",
    "    data = preprocessData(raw, dataset, 'tf_conv')\n",
    "    model = trainModel(data[0], 'tf_conv', dataset, load=True)\n",
    "    mods[dataset] = model\n",
    "    preds = runModel(data[1], model, ALGORITHM='tf_conv')\n",
    "    acc[dataset] = evalResults(data[1], preds, ALGORITHM='tf_conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the accuracy of the CNN was a tedious but rewarding task. At first, the CNN architecture for each dataset only had one convolution layer, followed by a dropout layer. This resulted in decent accuracy (95% for MINST datasets and 35%-50% for CIFAR datasets). To increase the accuracy further, I added more convolutional layers with increasing numbers of filters for each subsequent layer. Additionally, I added BatchNormalization layers to help with regularization and accelarating the training process. Lastly, despite the time complexity, I trained the CNNs for many epochs ~35. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 128,266\n",
      "Trainable params: 128,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mods['mnist_d'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_1_num_filters: 32     \n",
    "conv_2_num_filters: 64     \n",
    "conv_3_num_filters: 128     \n",
    "dropout: 0.2  \n",
    "num_hidden_layers = 1  \n",
    "neurons_per_hidden_layer = 256  \n",
    "pool_size = 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Fashion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               2654464   \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,760,746\n",
      "Trainable params: 2,759,850\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mods['mnist_f'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_1_num_filters: 32  \n",
    "conv_2_num_filters: 32   \n",
    "conv_3_num_filters: 64     \n",
    "conv_4_num_filters: 128     \n",
    "dropout: 0.2  \n",
    "num_hidden_layers = 1  \n",
    "neurons_per_hidden_layer = 256  \n",
    "pool_size = 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 26, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               3965184   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 4,072,042\n",
      "Trainable params: 4,071,146\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mods['cifar_10'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_1_num_filters: 32  \n",
    "conv_2_num_filters: 32   \n",
    "conv_3_num_filters: 64     \n",
    "conv_4_num_filters: 128     \n",
    "dropout: 0.2  \n",
    "num_hidden_layers = 1  \n",
    "neurons_per_hidden_layer = 256  \n",
    "pool_size = 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-100 (Coarse Labels)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 26, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               3965184   \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 4,074,612\n",
      "Trainable params: 4,073,716\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mods['cifar_100_c'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_1_num_filters: 32  \n",
    "conv_2_num_filters: 32   \n",
    "conv_3_num_filters: 64     \n",
    "conv_4_num_filters: 128     \n",
    "dropout: 0.2  \n",
    "num_hidden_layers = 1  \n",
    "neurons_per_hidden_layer = 256  \n",
    "pool_size = 2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-100 (Fine Labels)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CIFAR-100 dataset with fine labels, I used KerasTuner to optimize hyperparameters by building several models. The process is highlighted below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# note that data refers to the cifar_100_f dataset\n",
    "def buildTuneModel(hp):\n",
    "    mod = tf.keras.models.Sequential()\n",
    "    mod.add(tf.keras.layers.Conv2D(filters=hp.Int('input_num_filters', min_value=32, max_value=256, step=32),       kernel_size=(3, 3), activation=\"relu\", input_shape=data[0][0][0].shape))\n",
    "    mod.add(tf.keras.layers.BatchNormalization())\n",
    "    tf.keras.layers.Dropout(hp.Float('input_dropout',min_value=0.0,max_value=0.5,default=0.25,step=0.05))\n",
    "    for i in range(hp.Int('num_conv_layers', 1, 5)):\n",
    "        mod.add(tf.keras.layers.Conv2D(filters=hp.Int('conv_{i}_num_filters', min_value=32, max_value=256, step=32), kernel_size=(3, 3), activation=\"relu\"))\n",
    "        mod.add(tf.keras.layers.BatchNormalization())\n",
    "        mod.add(tf.keras.layers.Dropout(hp.Float('conv_{i}_dropout',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "    mod.add(tf.keras.layers.Flatten())\n",
    "    for i in range(hp.Int('num_hid_layers', 1, 5)):\n",
    "        mod.add(tf.keras.layers.Dense(hp.Int('hid_{i}_num_neurons', min_value=32, max_value=256, step=32), activation=\"relu\"))\n",
    "        mod.add(tf.keras.layers.BatchNormalization())\n",
    "        mod.add(tf.keras.layers.Dropout(hp.Float('hid_{i}_dropout',min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n",
    "    mod.add(tf.keras.layers.Dense(data[0][1].shape[1], activation=tf.nn.softmax))\n",
    "    mod.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return mod\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tuner = RandomSearch(buildTuneModel, objective='val_accuracy', max_trials=20, executions_per_trial=2)\n",
    "tuner.search_space_summary()\n",
    "tuner.search(x=data[0][0], y=data[0][1], epochs=3, validation_data=data[1])\n",
    "with open(f\"tuner.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the tuner and identify the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "with open(f'tuner.pkl', 'rb') as f:\n",
    "    tuner = pickle.load(f)\n",
    "    \n",
    "bestMod = tuner.get_best_models()[0]\n",
    "bestHps = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 192)       5376      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 96)        165984    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 96)        83040     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 96)        384       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64896)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 160)               10383520  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               16100     \n",
      "=================================================================\n",
      "Total params: 10,682,596\n",
      "Trainable params: 10,681,188\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bestMod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_num_filters: 192\n",
      "input_dropout: 0.2\n",
      "num_conv_layers: 2\n",
      "conv_{i}_num_filters: 96\n",
      "conv_{i}_dropout: 0.2\n",
      "num_hid_layers: 2\n",
      "hid_{i}_num_neurons: 160\n",
      "hid_{i}_dropout: 0.05\n"
     ]
    }
   ],
   "source": [
    "for hp in bestHps._hps.keys():\n",
    "    print('{}: {}'.format(hp, bestHps.get(hp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mnist_d\n",
      "Shape of xTrain dataset: (60000, 28, 28).\n",
      "Shape of yTrain dataset: (60000,).\n",
      "Shape of xTest dataset: (10000, 28, 28).\n",
      "Shape of yTest dataset: (10000,).\n",
      "New shape of xTrain dataset: (60000, 784).\n",
      "New shape of xTest dataset: (10000, 784).\n",
      "New shape of yTrain dataset: (60000, 10).\n",
      "New shape of yTest dataset: (10000, 10).\n",
      "Building and training TF_NN.\n",
      "Testing TF_NN.\n",
      "Classifier algorithm: tf_net\n",
      "Classifier accuracy: 98.020000%\n",
      "\n",
      "Dataset: mnist_f\n",
      "Shape of xTrain dataset: (60000, 28, 28).\n",
      "Shape of yTrain dataset: (60000,).\n",
      "Shape of xTest dataset: (10000, 28, 28).\n",
      "Shape of yTest dataset: (10000,).\n",
      "New shape of xTrain dataset: (60000, 784).\n",
      "New shape of xTest dataset: (10000, 784).\n",
      "New shape of yTrain dataset: (60000, 10).\n",
      "New shape of yTest dataset: (10000, 10).\n",
      "Building and training TF_NN.\n",
      "Testing TF_NN.\n",
      "Classifier algorithm: tf_net\n",
      "Classifier accuracy: 88.910000%\n",
      "\n",
      "Dataset: cifar_10\n",
      "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "Shape of yTrain dataset: (50000, 1).\n",
      "Shape of xTest dataset: (10000, 32, 32, 3).\n",
      "Shape of yTest dataset: (10000, 1).\n",
      "New shape of xTrain dataset: (50000, 3072).\n",
      "New shape of xTest dataset: (10000, 3072).\n",
      "New shape of yTrain dataset: (50000, 10).\n",
      "New shape of yTest dataset: (10000, 10).\n",
      "Building and training TF_NN.\n",
      "Testing TF_NN.\n",
      "Classifier algorithm: tf_net\n",
      "Classifier accuracy: 47.130000%\n",
      "\n",
      "Dataset: cifar_100_c\n",
      "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "Shape of yTrain dataset: (50000, 1).\n",
      "Shape of xTest dataset: (10000, 32, 32, 3).\n",
      "Shape of yTest dataset: (10000, 1).\n",
      "New shape of xTrain dataset: (50000, 3072).\n",
      "New shape of xTest dataset: (10000, 3072).\n",
      "New shape of yTrain dataset: (50000, 20).\n",
      "New shape of yTest dataset: (10000, 20).\n",
      "Building and training TF_NN.\n",
      "Testing TF_NN.\n",
      "Classifier algorithm: tf_net\n",
      "Classifier accuracy: 28.710000%\n",
      "\n",
      "Dataset: cifar_100_f\n",
      "Shape of xTrain dataset: (50000, 32, 32, 3).\n",
      "Shape of yTrain dataset: (50000, 1).\n",
      "Shape of xTest dataset: (10000, 32, 32, 3).\n",
      "Shape of yTest dataset: (10000, 1).\n",
      "New shape of xTrain dataset: (50000, 3072).\n",
      "New shape of xTest dataset: (10000, 3072).\n",
      "New shape of yTrain dataset: (50000, 100).\n",
      "New shape of yTest dataset: (10000, 100).\n",
      "Building and training TF_NN.\n",
      "Testing TF_NN.\n",
      "Classifier algorithm: tf_net\n",
      "Classifier accuracy: 13.520000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ann_acc = {'mnist_d':None, 'mnist_f':None, 'cifar_10':None, 'cifar_100_c':None, 'cifar_100_f':None}\n",
    "for dataset in ann_acc:\n",
    "    raw = getRawData(dataset)\n",
    "    data = preprocessData(raw, dataset, 'tf_net')\n",
    "    model = trainModel(data[0], 'tf_net', dataset, load=True)\n",
    "    preds = runModel(data[1], model, ALGORITHM='tf_net')\n",
    "    ann_acc[dataset] = evalResults(data[1], preds, ALGORITHM='tf_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(ann_acc.keys()), y=[acc*100 for acc in ann_acc.values()])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('ANN Accuracy')\n",
    "fig.savefig('ANN_Accuracy_Plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(acc.keys()), y=[acc*100 for acc in acc.values()])\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('CNN Accuracy')\n",
    "fig.savefig('CNN_Accuracy_Plot.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
